{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activating the virtual environment: source new_env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghulam/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-15 16:23:06.888312: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-15 16:23:06.902414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747326186.918998   44230 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747326186.923989   44230 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-15 16:23:06.941926: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 GPUs: ['Tesla T4', 'Tesla T4', 'Tesla T4', 'Tesla T4', 'Tesla T4']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def get_available_device():\n",
    "    \"\"\"Automatically selects multiple GPUs if available, otherwise falls back to CPU.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            # Get the number of available GPUs\n",
    "            num_gpus = torch.cuda.device_count()\n",
    "            device = torch.device(\"cuda\")  # Use all available GPUs\n",
    "            \n",
    "            print(f\"Using {num_gpus} GPUs: {[torch.cuda.get_device_name(i) for i in range(num_gpus)]}\")\n",
    "            return device\n",
    "        except Exception as e:\n",
    "            print(f\"GPU error: {str(e)}, falling back to CPU\")\n",
    "\n",
    "    return torch.device(\"cpu\")  # Default to CPU if no GPU is available\n",
    "\n",
    "# Example Usage\n",
    "device = get_available_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n",
      "8902\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)       # Should show a version like 12.1\n",
    "print(torch.backends.cudnn.version())  # Should print an integer version\n",
    "print(torch.cuda.is_available())       # Should be True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 GPUs: ['Tesla T4', 'Tesla T4', 'Tesla T4', 'Tesla T4', 'Tesla T4']\n",
      "Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "device = get_available_device()\n",
    "print(f\"Running on: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a custom PyTorch Dataset class called DeepfakeDataset â€” used for loading and preprocessing image data (e.g., for a deepfake detection task).\n",
    "\n",
    "This class enables your DataLoader to efficiently:\n",
    "\n",
    "Load each image\n",
    "\n",
    "Apply transformations (like resizing, normalization, etc.)\n",
    "\n",
    "Pair the image with its corresponding label (real or fake)\n",
    "\n",
    "\n",
    "__init__()\tInitializes dataset with image paths, labels, and transforms\n",
    "\n",
    "__len__()\tReturns number of total samples\n",
    "\n",
    "__getitem__()\tLoads, transforms, and returns an image-label pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 576, Validation samples: 144, Test samples: 140\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths to training and test datasets\n",
    "train_dir = \"/home/ghulam/FF++/cropped_face_mtcnn/train\"\n",
    "test_dir = \"/home/ghulam/FF++/cropped_face_mtcnn/test\"\n",
    "\n",
    "# Collect training images\n",
    "real_train_images = [os.path.join(train_dir, \"real\", img) for img in os.listdir(os.path.join(train_dir, \"real\"))]\n",
    "fake_train_images = [os.path.join(train_dir, \"fake\", img) for img in os.listdir(os.path.join(train_dir, \"fake\"))]\n",
    "\n",
    "# Combine images and assign labels (0 for real, 1 for fake)\n",
    "train_image_paths = real_train_images + fake_train_images\n",
    "train_labels = [0] * len(real_train_images) + [1] * len(fake_train_images)\n",
    "\n",
    "# Split training data into train and validation\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_image_paths, train_labels, test_size=0.2, stratify=train_labels\n",
    ")\n",
    "\n",
    "# Collect test images (not split, used separately)\n",
    "real_test_images = [os.path.join(test_dir, \"real\", img) for img in os.listdir(os.path.join(test_dir, \"real\"))]\n",
    "fake_test_images = [os.path.join(test_dir, \"fake\", img) for img in os.listdir(os.path.join(test_dir, \"fake\"))]\n",
    "\n",
    "test_paths = real_test_images + fake_test_images\n",
    "test_labels = [0] * len(real_test_images) + [1] * len(fake_test_images)\n",
    "\n",
    "print(f\"Train samples: {len(train_paths)}, Validation samples: {len(val_paths)}, Test samples: {len(test_paths)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation\tBefore\tAfter\n",
    "Resize (224, 224)\tAny size (e.g., 512x512)\t224 x 224\n",
    "ToTensor\tPIL Image / NumPy array\tPyTorch tensor (C x H x W)\n",
    "Normalize\tValues in [0, 1]\tCentered around 0 with small std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images for both models\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # average pixel values from the ImageNet dataset, which pretrained models were trained on\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component\tPurpose\n",
    "\n",
    "__init__\tCollects image paths and assigns numeric labels for each subfolder\n",
    "\n",
    "__len__\tReturns total number of images\n",
    "\n",
    "__getitem__\tOpens an image, applies transforms, returns image + label\n",
    "\n",
    "transform\tStandard preprocessing for model compatibility\n",
    "convert(\"RGB\")\tEnsures all images have 3 channels (even grayscale ones)\n",
    "labeling logic\tAuto-assigns 0, 1, ... to class folders using enumerate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Traverse the nested folder structure\n",
    "        for label, subdir in enumerate(os.listdir(root_dir)):\n",
    "            subdir_path = os.path.join(root_dir, subdir)\n",
    "            if os.path.isdir(subdir_path):\n",
    "                for img_name in os.listdir(subdir_path):\n",
    "                    img_path = os.path.join(subdir_path, img_name)\n",
    "                    if os.path.isfile(img_path):\n",
    "                        self.image_paths.append(img_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Pertrained efficientnet B3\n",
    "\n",
    "Section\t                                           Purpose\n",
    "Load Pretrained Model\t                Use efficientnet_b3 trained on ImageNet\n",
    "Modify Classifier\t                    Change output layer to fit binary classification\n",
    "Set Device\t                            Automatically use GPU if available\n",
    "Use Multi-GPU\t                        Wrap with DataParallel if multiple GPUs are found\n",
    "Move Model to Device\t                Ensures model is ready to train on selected device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghulam/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ghulam/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): EfficientNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (8): Conv2dNormActivation(\n",
       "        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.3, inplace=True)\n",
       "      (1): Linear(in_features=1536, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# Load EfficientNet-B3\n",
    "efficientnet = models.efficientnet_b3(pretrained=True)\n",
    "\n",
    "# Modify classifier for binary classification\n",
    "efficientnet.classifier[1] = nn.Linear(efficientnet.classifier[1].in_features, 2)\n",
    "\n",
    "# Check if multiple GPUs are available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    efficientnet = nn.DataParallel(efficientnet)  # Distribute model across multiple GPUs\n",
    "\n",
    "# Move model to GPU(s)\n",
    "efficientnet.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step\t                                            Purpose\n",
    "\n",
    "Load ViTConfig\t                       Configure the model structure with binary classification (2 labels)\n",
    "\n",
    "Load Pretrained ViT\t                   Load ImageNet-pretrained ViT model, ignoring classifier size mismatch\n",
    "\n",
    "Replace Classifier\t                   Manually override the classifier to fit your use case\n",
    "\n",
    "Setup GPU Device\t                   Auto-detects and uses CUDA GPU\n",
    "\n",
    "Enable Multi-GPU\t                   Parallelizes training if more than one GPU is available\n",
    "\n",
    "Move to Device\t                       Deploys model on CPU or GPU(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghulam/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ViTForImageClassification(\n",
       "    (vit): ViTModel(\n",
       "      (embeddings): ViTEmbeddings(\n",
       "        (patch_embeddings): ViTPatchEmbeddings(\n",
       "          (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): ViTEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x ViTLayer(\n",
       "            (attention): ViTAttention(\n",
       "              (attention): ViTSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): ViTSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ViTIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): ViTOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "\n",
    "# Step 1: Load the model configuration\n",
    "config = ViTConfig.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "config.num_labels = 2  # Set the number of output labels for binary classification\n",
    "\n",
    "# Step 2: Load the pretrained model\n",
    "vit = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    config=config,\n",
    "    ignore_mismatched_sizes=True,  # Ignore the size mismatch for the classifier\n",
    ")\n",
    "\n",
    "# Step 3: Replace the classifier\n",
    "vit.classifier = nn.Linear(vit.config.hidden_size, config.num_labels)\n",
    "\n",
    "# Step 4: Enable Multi-GPU training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    vit = nn.DataParallel(vit)  # Distributes model across multiple GPUs\n",
    "\n",
    "# Move model to GPU(s)\n",
    "vit.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase\t                                   What Happens\n",
    "Setup\t                         Move model to device and wrap with DataParallel if needed\n",
    "Training\t                     Forward pass, loss calculation, backward pass, optimizer step\n",
    "Evaluation\t                     Inference only, no gradient update\n",
    "Metrics\t                         Track loss and accuracy for both training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_model(model, optimizer, criterion, train_loader, val_loader, epochs, device):\n",
    "    model.to(device)  # Move model to GPU(s)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs for training!\")\n",
    "        model = nn.DataParallel(model)  # Distributes model across multiple GPUs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() #Clears out the old gradients before a new backward pass\n",
    "            outputs = model(images)  # DataParallel automatically distributes inputs\n",
    "            logits = outputs.logits if isinstance(outputs, dict) else outputs  # handles both dict outputs (ViT) and normal outputs (e.g., EfficientNet)\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            correct += (logits.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss /= total\n",
    "        train_accuracy = correct / total\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                logits = outputs.logits if isinstance(outputs, dict) else outputs  # handles both dict outputs (ViT) and normal outputs (e.g., EfficientNet)\n",
    "                \n",
    "                loss = criterion(logits, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                correct += (logits.argmax(1) == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_loss /= total\n",
    "        val_accuracy = correct / total\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line\t                             Action\t                               Why it's important\n",
    "torch.device(...)\t                Set device\t                       Portability across CPU/GPU\n",
    "nn.DataParallel(...)\t            Enable multi-GPU training\t       Speeds up training, handles large batches\n",
    "model.to(device)\t                Move model to hardware\t           Ensures computations run on chosen device\n",
    "CrossEntropyLoss()\t                Loss function for classification   Handles multi-class or binary logits\n",
    "torch.optim.Adam(...)\t            Optimizer\t                       Adaptive and efficient for transformer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 GPUs!\n"
     ]
    }
   ],
   "source": [
    "# Set device for multiple GPUs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Wrap the model with DataParallel for multi-GPU usage\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    vit = nn.DataParallel(vit)  # Distributes model across all available GPUs\n",
    "\n",
    "# Move model to GPU(s)\n",
    "vit.to(device)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "vit_optimizer = torch.optim.Adam(vit.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward(self, x): The core of the model. This method defines how the input data flows through the network.\n",
    "\n",
    "x is the input tensor (batch of images).\n",
    "\n",
    "EfficientNet Feature Extraction: The input is passed through the EfficientNet backbone (excluding the classifier) to extract features.\n",
    "\n",
    "Adaptive AvgPool: After feature extraction, an adaptive average pooling layer is used to pool the output into a fixed size (1x1), regardless of the input image size.\n",
    "\n",
    "eff_features.view(...): Flattens the pooled features into a 1D vector.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This code defines a custom combined model that uses both EfficientNet-B3 (for feature extraction) and ViT (Vision Transformer).\n",
    "\n",
    "EfficientNet processes the image to generate feature maps, while ViT extracts global features via its CLS token.\n",
    "\n",
    "The two feature sets are concatenated and passed through a fully connected layer for binary classification.\n",
    "\n",
    "The model supports multi-GPU training via DataParallel and moves the model to the GPU using .to(device)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet expected features: 1536\n",
      "ViT expected features: 768\n",
      "Combined features expected: 2304\n",
      "Using 5 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CombinedModel(\n",
       "    (efficientnet): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "                (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n",
       "          )\n",
       "          (3): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)\n",
       "          )\n",
       "          (4): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)\n",
       "          )\n",
       "          (3): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)\n",
       "          )\n",
       "          (4): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n",
       "          )\n",
       "          (3): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)\n",
       "          )\n",
       "          (4): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n",
       "          )\n",
       "          (5): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "                (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (8): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (vit): ViTForImageClassification(\n",
       "      (vit): ViTModel(\n",
       "        (embeddings): ViTEmbeddings(\n",
       "          (patch_embeddings): ViTPatchEmbeddings(\n",
       "            (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (encoder): ViTEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "    (efficientnet_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=2304, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from transformers import ViTForImageClassification\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, efficientnet, vit):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.efficientnet = nn.Sequential(*list(efficientnet.children())[:-2])  # Remove classifier\n",
    "        \n",
    "        # Store the full ViT model\n",
    "        self.vit = vit\n",
    "        \n",
    "        # Extract correct feature sizes\n",
    "        self.efficientnet_avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        eff_features_dim = 1536  # EfficientNet-B3 output size\n",
    "        vit_features_dim = vit.config.hidden_size  # ViT hidden size (768)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(eff_features_dim + vit_features_dim, 2)\n",
    "        \n",
    "        # Print expected dimensions\n",
    "        print(f\"EfficientNet expected features: {eff_features_dim}\")\n",
    "        print(f\"ViT expected features: {vit_features_dim}\")\n",
    "        print(f\"Combined features expected: {eff_features_dim + vit_features_dim}\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Print input shape\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        \n",
    "        # EfficientNet feature extraction\n",
    "        eff_features = self.efficientnet(x)\n",
    "        print(f\"EfficientNet features before pooling: {eff_features.shape}\")\n",
    "        \n",
    "        eff_features = self.efficientnet_avgpool(eff_features)\n",
    "        print(f\"EfficientNet features after pooling: {eff_features.shape}\")\n",
    "        \n",
    "        eff_features = eff_features.view(eff_features.size(0), -1)  # (batch_size, 1536)\n",
    "        print(f\"EfficientNet features after flattening: {eff_features.shape}\")\n",
    "        \n",
    "        # Process input for ViT if needed\n",
    "        if x.shape[-1] != 224 or x.shape[-2] != 224:\n",
    "            vit_input = F.interpolate(x, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "            print(f\"Resized input for ViT: {vit_input.shape}\")\n",
    "        else:\n",
    "            vit_input = x\n",
    "            print(f\"Original input for ViT: {vit_input.shape}\")\n",
    "            \n",
    "        # Get ViT features using output_hidden_states\n",
    "        vit_outputs = self.vit(vit_input, output_hidden_states=True)\n",
    "        \n",
    "        # Get the CLS token from the last hidden state\n",
    "        vit_features = vit_outputs.hidden_states[-1][:, 0]\n",
    "        print(f\"ViT features shape: {vit_features.shape}\")\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat((eff_features, vit_features), dim=1)\n",
    "        print(f\"Combined features shape: {combined_features.shape}\")\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.fc(combined_features)\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Multi-GPU Support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "efficientnet = models.efficientnet_b3(pretrained=True)  # Load EfficientNet-B3\n",
    "efficientnet.classifier[1] = nn.Linear(efficientnet.classifier[1].in_features, 2)  # Modify for binary classification\n",
    "\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "vit = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "vit.classifier = nn.Linear(vit.config.hidden_size, 2)  # Modify classifier for binary classification\n",
    "\n",
    "model = CombinedModel(efficientnet, vit)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)  \n",
    "\n",
    "model.to(device)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet feature dim: 1536\n",
      "ViT feature dim: 768\n",
      "Combined features dim: 2304\n",
      "Using 5 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CombinedModel(\n",
       "    (efficientnet): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "                (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n",
       "          )\n",
       "          (3): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)\n",
       "          )\n",
       "          (4): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)\n",
       "          )\n",
       "          (3): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)\n",
       "          )\n",
       "          (4): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n",
       "          )\n",
       "          (3): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)\n",
       "          )\n",
       "          (4): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n",
       "          )\n",
       "          (5): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "                (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (8): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (vit): ViTForImageClassification(\n",
       "      (vit): ViTModel(\n",
       "        (embeddings): ViTEmbeddings(\n",
       "          (patch_embeddings): ViTPatchEmbeddings(\n",
       "            (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (encoder): ViTEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "    (efficientnet_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=2304, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForImageClassification, AutoConfig\n",
    "from torchvision import models\n",
    "\n",
    "# Load EfficientNet-B3\n",
    "efficientnet = models.efficientnet_b3(pretrained=True)\n",
    "\n",
    "# Load Vision Transformer (ViT) with Custom Config\n",
    "config = AutoConfig.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "config.num_labels = 2  # Update for binary classification\n",
    "vit = AutoModelForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\", \n",
    "    config=config, \n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Define Combined Model\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, efficientnet, vit):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.efficientnet = nn.Sequential(*list(efficientnet.children())[:-2])  # Remove classifier\n",
    "        self.vit = vit  # Store the full ViT model\n",
    "        \n",
    "        # Extract correct feature sizes\n",
    "        self.efficientnet_avgpool = nn.AdaptiveAvgPool2d(1)  # Pool to (batch_size, 1536, 1, 1)\n",
    "        eff_features_dim = 1536  # EfficientNet-B3 output size\n",
    "        vit_features_dim = vit.config.hidden_size  # ViT hidden size (768)\n",
    "        \n",
    "        # Print dimensions for debugging\n",
    "        print(f\"EfficientNet feature dim: {eff_features_dim}\")\n",
    "        print(f\"ViT feature dim: {vit_features_dim}\")\n",
    "        print(f\"Combined features dim: {eff_features_dim + vit_features_dim}\")\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(eff_features_dim + vit_features_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        # EfficientNet feature extraction\n",
    "        eff_features = self.efficientnet(x)\n",
    "        print(f\"EfficientNet features before pooling: {eff_features.shape}\")\n",
    "        eff_features = self.efficientnet_avgpool(eff_features)\n",
    "        print(f\"EfficientNet features after pooling: {eff_features.shape}\")\n",
    "        eff_features = eff_features.view(eff_features.size(0), -1)  # (batch_size, 1536)\n",
    "        print(f\"EfficientNet features after flattening: {eff_features.shape}\")\n",
    "        \n",
    "        # Resize input for ViT (224x224)\n",
    "        vit_input = F.interpolate(x, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "        print(f\"ViT input shape: {vit_input.shape}\")\n",
    "        \n",
    "        # Use the ViT model with return_dict=True to ensure consistent output structure\n",
    "        vit_outputs = self.vit(vit_input, output_hidden_states=True, return_dict=True)\n",
    "        \n",
    "        # Access hidden states correctly - the structure depends on the model version\n",
    "        if hasattr(vit_outputs, 'hidden_states') and vit_outputs.hidden_states is not None:\n",
    "            # Get the CLS token from the last hidden state\n",
    "            vit_features = vit_outputs.hidden_states[-1][:, 0]\n",
    "        else:\n",
    "            # For some versions, we might need to access it differently\n",
    "            # Use the pooler output as fallback\n",
    "            vit_features = vit_outputs.pooler_output\n",
    "            \n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat((eff_features, vit_features), dim=1)\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.fc(combined_features)\n",
    "        print(f\"ViT features shape: {vit_features.shape}\")\n",
    "        print(f\"Combined features shape: {combined_features.shape}\")\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        return output\n",
    "\n",
    "# Device & Multi-GPU Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CombinedModel(efficientnet, vit)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)  \n",
    "\n",
    "model.to(device) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're not repeating anything unnecessarily. The flow is actually proper:\n",
    "\n",
    "Load pretrained EfficientNet and ViT â†’ done at the top.\n",
    "\n",
    "Define your CombinedModel class â†’ done in the middle.\n",
    "\n",
    "Instantiate the CombinedModel with the loaded backbones.\n",
    "\n",
    "Prepare it for training with device & multi-GPU setup â†’ done at the end.\n",
    "\n",
    "It might seem like a re-init, but it's a sequential and logical progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CombinedModel(\n",
       "    (efficientnet): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "                (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "                (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n",
       "          )\n",
       "          (3): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)\n",
       "          )\n",
       "          (4): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)\n",
       "          )\n",
       "          (3): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)\n",
       "          )\n",
       "          (4): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "                (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n",
       "          )\n",
       "          (3): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)\n",
       "          )\n",
       "          (4): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n",
       "          )\n",
       "          (5): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "                (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "                (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (8): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (vit): ViTForImageClassification(\n",
       "      (vit): ViTModel(\n",
       "        (embeddings): ViTEmbeddings(\n",
       "          (patch_embeddings): ViTPatchEmbeddings(\n",
       "            (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (encoder): ViTEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "    (efficientnet_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=2304, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the combined model\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, efficientnet, vit):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.efficientnet = nn.Sequential(*list(efficientnet.children())[:-2])  # Remove classifier\n",
    "        self.vit = vit  # Store the full ViT model\n",
    "        \n",
    "        # Extract correct feature sizes\n",
    "        self.efficientnet_avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        eff_features_dim = 1536  # EfficientNet-B3 output size\n",
    "        vit_features_dim = vit.config.hidden_size  # ViT hidden size\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(eff_features_dim + vit_features_dim, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # EfficientNet feature extraction\n",
    "        eff_features = self.efficientnet(x)\n",
    "        eff_features = self.efficientnet_avgpool(eff_features)\n",
    "        eff_features = eff_features.view(eff_features.size(0), -1)  # (batch_size, 1536)\n",
    "        \n",
    "        # Resize input for ViT if needed\n",
    "        vit_input = F.interpolate(x, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "        \n",
    "        # Get ViT features using the full model with return_dict=True for consistent output structure\n",
    "        vit_outputs = self.vit(vit_input, output_hidden_states=True, return_dict=True)\n",
    "        \n",
    "        # Access hidden states correctly - handle different model versions\n",
    "        if hasattr(vit_outputs, 'hidden_states') and vit_outputs.hidden_states is not None:\n",
    "            # Get the CLS token from the last hidden state\n",
    "            vit_features = vit_outputs.hidden_states[-1][:, 0]  # Shape: (batch_size, 768)\n",
    "        else:\n",
    "            # Fallback to pooler output if hidden_states not available\n",
    "            vit_features = vit_outputs.pooler_output\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat((eff_features, vit_features), dim=1)  # (batch_size, 2304)\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.fc(combined_features)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Instantiate the combined model\n",
    "combined_model = CombinedModel(efficientnet, vit)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    combined_model = nn.DataParallel(combined_model)  \n",
    "combined_model.to(device)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code\t                                         Purpose\n",
    "nn.CrossEntropyLoss()\t              Used to calculate classification loss based on predicted logits and true labels\n",
    "torch.optim.Adam(...)\t              Optimizes model weights during training\n",
    ".parameters()\t                      Tells the optimizer which tensors to update\n",
    ".module.parameters()\t              Needed if model is wrapped in nn.DataParallel\n",
    "lr=1e-4\t                              Learning rate for controlling how fast the optimizer updates weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (Handle DataParallel case)\n",
    "optimizer = torch.optim.Adam(combined_model.module.parameters() if isinstance(combined_model, nn.DataParallel) else combined_model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component\t                                                Purpose\n",
    "CustomImageDataset\t               A custom PyTorch dataset to load images and labels from a nested folder structure\n",
    "__init__()\t                       Traverses folder structure, assigns labels, and stores paths\n",
    "__getitem__()\t                   Loads a single image, applies transforms, and returns it with label\n",
    "get_data_loader()\t               Utility to create DataLoader with batching, shuffling, multiprocessing\n",
    "DataLoader\t                       Feeds your model batches of (image, label) pairs efficiently, with multi-core support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # Assign labels based on top-level directories\n",
    "        label_mapping = { \"fake\": 0, \"real\": 1 }\n",
    "\n",
    "        # Traverse the nested folder structure\n",
    "        for label_name, label in label_mapping.items():\n",
    "            label_dir = os.path.join(root_dir, label_name)\n",
    "            if os.path.isdir(label_dir):\n",
    "                for subdir in os.listdir(label_dir):\n",
    "                    subdir_path = os.path.join(label_dir, subdir)\n",
    "                    if os.path.isdir(subdir_path):\n",
    "                        for file_name in os.listdir(subdir_path):\n",
    "                            file_path = os.path.join(subdir_path, file_name)\n",
    "                            if os.path.isfile(file_path):\n",
    "                                self.image_paths.append(file_path)\n",
    "                                self.labels.append(label)\n",
    "\n",
    "        print(f\"Loaded {len(self.image_paths)} images from {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Use DataLoader for Multi-GPU training\n",
    "def get_data_loader(root_dir, transform, batch_size=32, num_workers=4):\n",
    "    dataset = CustomImageDataset(root_dir, transform=transform)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block\t                                  Purpose\n",
    "Transform\t                  Resize & normalize images before feeding to model\n",
    "CustomImageDataset\t          Load image-label pairs from folder structure\n",
    "DataLoader\t                  Efficiently batch and load training/validation images\n",
    "DataParallel\t              Enable training across multiple GPUs (if available)\n",
    ".to(device)\t                  Move model to GPU(s) for actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21595 images from /home/ghulam/FF++/cropped_face_mtcnn/train\n",
      "Loaded 4196 images from /home/ghulam/FF++/cropped_face_mtcnn/val\n",
      "Using 5 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): DataParallel(\n",
       "    (module): CombinedModel(\n",
       "      (efficientnet): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "                  (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (2): Conv2dNormActivation(\n",
       "                  (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "            )\n",
       "            (1): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "                  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (2): Conv2dNormActivation(\n",
       "                  (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "                  (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)\n",
       "            )\n",
       "            (1): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                  (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)\n",
       "            )\n",
       "            (2): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                  (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "                  (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)\n",
       "            )\n",
       "            (1): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "                  (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)\n",
       "            )\n",
       "            (2): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "                  (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)\n",
       "            )\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "                  (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)\n",
       "            )\n",
       "            (1): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                  (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)\n",
       "            )\n",
       "            (2): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                  (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n",
       "            )\n",
       "            (3): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                  (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)\n",
       "            )\n",
       "            (4): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                  (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)\n",
       "            )\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "                  (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "            )\n",
       "            (1): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                  (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n",
       "            )\n",
       "            (2): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                  (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)\n",
       "            )\n",
       "            (3): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                  (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)\n",
       "            )\n",
       "            (4): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "                  (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)\n",
       "            )\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "                  (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n",
       "            )\n",
       "            (1): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)\n",
       "            )\n",
       "            (2): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n",
       "            )\n",
       "            (3): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)\n",
       "            )\n",
       "            (4): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n",
       "            )\n",
       "            (5): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)\n",
       "            )\n",
       "          )\n",
       "          (7): Sequential(\n",
       "            (0): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "                  (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)\n",
       "            )\n",
       "            (1): MBConv(\n",
       "              (block): Sequential(\n",
       "                (0): Conv2dNormActivation(\n",
       "                  (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv2dNormActivation(\n",
       "                  (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "                  (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (2): SiLU(inplace=True)\n",
       "                )\n",
       "                (2): SqueezeExcitation(\n",
       "                  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (activation): SiLU(inplace=True)\n",
       "                  (scale_activation): Sigmoid()\n",
       "                )\n",
       "                (3): Conv2dNormActivation(\n",
       "                  (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)\n",
       "            )\n",
       "          )\n",
       "          (8): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (vit): ViTForImageClassification(\n",
       "        (vit): ViTModel(\n",
       "          (embeddings): ViTEmbeddings(\n",
       "            (patch_embeddings): ViTPatchEmbeddings(\n",
       "              (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (encoder): ViTEncoder(\n",
       "            (layer): ModuleList(\n",
       "              (0-11): 12 x ViTLayer(\n",
       "                (attention): ViTAttention(\n",
       "                  (attention): ViTSelfAttention(\n",
       "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): ViTSelfOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): ViTIntermediate(\n",
       "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): ViTOutput(\n",
       "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "      (efficientnet_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Linear(in_features=2304, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Update Transformations for EfficientNet-B3 (300x300 input size)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load Datasets\n",
    "train_dataset = CustomImageDataset(root_dir='/home/ghulam/FF++/cropped_face_mtcnn/train', transform=transform)\n",
    "val_dataset = CustomImageDataset(root_dir='/home/ghulam/FF++/cropped_face_mtcnn/val', transform=transform)\n",
    "\n",
    "# Optimize DataLoader for Multi-GPU Training\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "# Move Model to GPUs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)  \n",
    "model.to(device)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature\t                                                Purpose\n",
    "GradScaler + autocast()\t                    Mixed precision training (fast + memory efficient)\n",
    "model.train() / model.eval()\t            Switch between training/eval modes\n",
    "DataParallel\t                            Use multiple GPUs automatically\n",
    "no_grad()\t                                Save memory during validation\n",
    "argmax(1)\t                                Get predicted class labels\n",
    ".item()\t                                    Convert tensors to Python scalars\n",
    "to(device)\t                                Move everything to GPU (or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 GPUs!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Use Mixed Precision for Faster Training\n",
    "scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "def train_combined_model(model, train_loader, val_loader, criterion, optimizer, epochs, device):\n",
    "    model.to(device)  # Move model to GPU(s)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss, correct = 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU(s)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Use AMP for Efficient Training\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_accuracy = correct / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss, correct = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)  # Move data to GPU(s)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        val_accuracy = correct / len(val_loader.dataset)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Multi-GPU Training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)  # Enables training on all available GPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167383/3450114499.py:21: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 33.6293, Train Accuracy: 0.9607\n",
      "Validation Loss: 16.4292, Validation Accuracy: 0.9261\n",
      "Epoch 2, Train Loss: 3.4864, Train Accuracy: 0.9968\n",
      "Validation Loss: 4.7842, Validation Accuracy: 0.9771\n",
      "Epoch 3, Train Loss: 1.2266, Train Accuracy: 0.9989\n",
      "Validation Loss: 11.9484, Validation Accuracy: 0.9659\n",
      "Epoch 4, Train Loss: 5.7996, Train Accuracy: 0.9939\n",
      "Validation Loss: 3.2974, Validation Accuracy: 0.9843\n",
      "Epoch 5, Train Loss: 2.4096, Train Accuracy: 0.9975\n",
      "Validation Loss: 5.5837, Validation Accuracy: 0.9781\n"
     ]
    }
   ],
   "source": [
    "# Use Multi-GPU and Mixed Precision\n",
    "train_combined_model(\n",
    "    model=combined_model.to(device),  # Move model to GPU(s)\n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader,          \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    epochs=5,\n",
    "    device=device  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your best model (e.g., after training)\n",
    "torch.save(combined_model.state_dict(), 'best_combined_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component\t                                                   Purpose\n",
    "transforms\t                                           Resize and normalize images\n",
    "DataLoader\t                                           Loads data efficiently in batches\n",
    "model.eval()\t                                       Turns off dropout and batchnorm during inference\n",
    "torch.no_grad()\t                                       Saves memory by disabling gradient calculations\n",
    "torch.cuda.amp.autocast()\t                           Mixed precision â†’ faster and more efficient inference\n",
    "torch.max()\t                                           Gets predicted class from output logits\n",
    "classification_report\t                               Gives detailed performance metrics (Precision, Recall, F1)\n",
    "confusion_matrix\t                                   Shows where the model made right or wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4200 images from /home/ghulam/FF++/cropped_face_mtcnn/test\n",
      "Using 5 GPUs for testing!\n",
      "Test Accuracy: 81.60%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.74      0.97      0.84      2100\n",
      "        Fake       0.96      0.66      0.78      2100\n",
      "\n",
      "    accuracy                           0.82      4200\n",
      "   macro avg       0.85      0.82      0.81      4200\n",
      "weighted avg       0.85      0.82      0.81      4200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2045   55]\n",
      " [ 718 1382]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define test transformation (same as training)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),  # EfficientNet-B3 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = CustomImageDataset(root_dir='/home/ghulam/FF++/cropped_face_mtcnn/test', \n",
    "                                 transform=test_transform)\n",
    "\n",
    "# Create test DataLoader with optimal settings for multi-GPU\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                        batch_size=64,  \n",
    "                        shuffle=False,  \n",
    "                        num_workers=8,  \n",
    "                        pin_memory=True)  \n",
    "def test_combined_model(model, test_loader, device):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Update metrics\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store predictions and labels for additional metrics\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    return accuracy, all_preds, all_labels\n",
    "\n",
    "# Load your trained model\n",
    "combined_model = CombinedModel(efficientnet, vit)\n",
    "combined_model.load_state_dict(torch.load('/home/ghulam/FF++/DeepfakeImageDetectionApp_ver1.0/best_combined_model.pth'))\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Enable multi-GPU testing\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs for testing!\")\n",
    "    combined_model = nn.DataParallel(combined_model)\n",
    "\n",
    "# Move model to device\n",
    "combined_model.to(device)\n",
    "\n",
    "# Run testing\n",
    "accuracy, predictions, true_labels = test_combined_model(combined_model, test_loader, device)\n",
    "\n",
    "# Optional: Calculate additional metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=['Real', 'Fake']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15457 images from /home/ghulam/Celeb-DF/test\n",
      "Using 5 GPUs for testing!\n",
      "Test Accuracy: 65.17%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.66      0.99      0.79     10133\n",
      "        Fake       0.35      0.01      0.03      5324\n",
      "\n",
      "    accuracy                           0.65     15457\n",
      "   macro avg       0.50      0.50      0.41     15457\n",
      "weighted avg       0.55      0.65      0.53     15457\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10001   132]\n",
      " [ 5252    72]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define test transformation (same as training)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),  # EfficientNet-B3 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = CustomImageDataset(root_dir='/home/ghulam/Celeb-DF/test', \n",
    "                                 transform=test_transform)\n",
    "\n",
    "# Create test DataLoader with optimal settings for multi-GPU\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                        batch_size=64,  \n",
    "                        shuffle=False,  \n",
    "                        num_workers=8,  \n",
    "                        pin_memory=True)  \n",
    "def test_combined_model(model, test_loader, device):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Update metrics\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store predictions and labels for additional metrics\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    return accuracy, all_preds, all_labels\n",
    "\n",
    "# Load your trained model\n",
    "combined_model = CombinedModel(efficientnet, vit)\n",
    "combined_model.load_state_dict(torch.load('/home/ghulam/FF++/DeepfakeImageDetectionApp_ver1.0/best_combined_model.pth'))\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Enable multi-GPU testing\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs for testing!\")\n",
    "    combined_model = nn.DataParallel(combined_model)\n",
    "\n",
    "# Move model to device\n",
    "combined_model.to(device)\n",
    "\n",
    "# Run testing\n",
    "accuracy, predictions, true_labels = test_combined_model(combined_model, test_loader, device)\n",
    "\n",
    "# Optional: Calculate additional metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=['Real', 'Fake']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
